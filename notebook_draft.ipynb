{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Project 3. The Adoption of EVs**\n",
    "> **(Team 3) Lucas Perez, Sultan Raheem, Mahind Rao, Rachel Schoen | Data Engineering Track**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I. **Introduction**\n",
    "* *   * * "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this project, we sought to engineer a database to help answer the following questions:\n",
    "\n",
    "> **How does the presence and accessibility of electric vehicle (EV) charging infrastructure impact the adoption of EVs and contribute to reducing carbon emissions across different regions?**\n",
    "\n",
    "- How does the availability and accessibility of EV charging stations correlate with the adoption rates of electric vehicles in various counties?\n",
    "- What are the usage patterns of EVs in regions with high versus low access to EV charging stations, and how does this access impact the distribution and primary use of EVs?\n",
    "- What is the relationship between the increase in the number of EV charging stations and the reduction in carbon emissions by facilities within those regions?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* *   * * \n",
    "> #### **Why choose SQL Database?**\n",
    "When deciding whether to choose a SQL database over a non-SQL (NoSQL) database, several factors come into play:\n",
    "\n",
    "1. **Structured Data**: SQL databases are well-suited for structured data, which is typical in scenarios involving relational data such as geographical locations of charging stations, adoption rates of EVs, emission data over time, etc. The structured nature of SQL databases ensures that relationships between different types of data (e.g., charging station data, adoption rates, emissions data) can be easily defined and maintained.\n",
    "\n",
    "2. **Complex Queries**: If your analysis involves complex queries that require joins across multiple tables or aggregations (e.g., calculating average adoption rates by region, correlating charging station density with emission reductions), SQL's powerful querying capabilities make it easier to perform such operations efficiently.\n",
    "\n",
    "3. **Data Integrity and ACID Compliance**: SQL databases typically enforce ACID (Atomicity, Consistency, Isolation, Durability) properties, which ensure data integrity even in the event of system failures or concurrent access. This is crucial when handling data that needs to be accurate and consistent, especially in applications where data integrity is critical, such as research on environmental impact and policy decisions.\n",
    "\n",
    "4. **Scalability for Structured Data**: While traditionally SQL databases were perceived as less scalable than NoSQL databases for large-scale data operations, modern SQL databases have evolved to handle large volumes of structured data efficiently. With proper indexing, partitioning, and clustering strategies, SQL databases can scale well for the size and complexity of data typically found in studies involving regional impact analysis.\n",
    "\n",
    "5. **Maturity and Ecosystem**: SQL databases have been widely used for decades and have a mature ecosystem of tools, libraries, and support. This makes it easier to find expertise, integrate with other systems, and ensure long-term maintenance and scalability of the database.\n",
    "\n",
    "In summary, for a database focused on analyzing the impact of EV charging infrastructure on EV adoption and carbon emissions across different regions, choosing a SQL database would typically be advantageous due to its suitability for handling structured data, supporting complex queries, ensuring data integrity, and leveraging a mature ecosystem of tools and support.\n",
    "\n",
    "* *   * * \n",
    "> #### **Ethical Considerations**\n",
    "\n",
    "Designing a database around the impact of EV charging infrastructure on EV adoption and carbon emissions across regions involves several ethical considerations:\n",
    "\n",
    "1. **Privacy and Data Protection**: \n",
    "   - **Personal Data**: Ensure that any personally identifiable information (PII) collected, such as user demographics or specific location data, is anonymized or pseudonymized to protect individual privacy. This condition is fulfilled as vehicles are identified by their identification number (VIN), negating the need for any names or specific addresses of drivers that could potentially be leaked. By using county data as opposed to addresses, we are able to localize to slightly more generalized locations within a state population (Washington) without too much generalization that could skew the data.\n",
    "\n",
    "2. **Bias and Fairness**:\n",
    "   - **Data Bias**: Be aware of potential biases in the data collected, such as demographic biases in EV adoption rates or charging station accessibility. Take steps to mitigate biases to ensure fair analysis and conclusions.\n",
    "   - **Algorithmic Bias**: If using algorithms for data analysis, ensure they are designed to avoid bias and to provide fair and equitable results across different demographic groups and regions.\n",
    "\n",
    "3. **Transparency and Accountability**:\n",
    "   - **Data Transparency**: Be transparent about the sources of data, methodologies used for analysis, and any assumptions made in the study. This transparency helps in validating the results and building trust in the findings.\n",
    "   - **Accountability**: Take responsibility for the accuracy and implications of the data and analyses. Ensure that stakeholders can understand and question the methodologies and interpretations used in the database design.\n",
    "\n",
    "4. **Environmental Impact**:\n",
    "   - Consider the environmental impact of data collection and storage practices. Optimize database design and operations to minimize energy consumption and carbon footprint, especially if hosting large-scale databases and conducting extensive data analysis.\n",
    "\n",
    "5. **Benefit and Harm**:\n",
    "   - Assess the potential benefits and harms of the research and database usage. Ensure that the research contributes positively to understanding and addressing environmental challenges without causing harm to individuals or communities.\n",
    "\n",
    "6. **Data Ownership and Governance**:\n",
    "   - Clearly define data ownership and governance policies, especially if collaborating with multiple stakeholders or using data from different sources. Respect data ownership rights and ensure that data usage aligns with ethical guidelines and legal regulations.\n",
    "\n",
    "7. **Public Interest and Impact**:\n",
    "   - Consider the broader public interest and impact of the research and database findings. Ensure that the results are communicated accurately and responsibly to inform policy decisions and public discourse on EV adoption and carbon emissions reduction.\n",
    "\n",
    "By addressing these ethical considerations during the design and implementation of the database, researchers and practitioners can ensure that their work is conducted ethically, respects privacy and fairness, and contributes positively to addressing environmental challenges associated with EV adoption and carbon emissions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II. **Database Design**\n",
    "* *   * * "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following is the ERDV diagram of our database.\n",
    "\n",
    "Each table is anchored by the Vehicle Identification Number (VIN), a Unique ID for each charging station, a Unique ID for each faculty, and a unique Event ID for the history of the population size of EV in Washington State.\n",
    "\n",
    "![Image of ERDV](https://i.imgur.com/aVVrlMm.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are four tables in total for this database:\n",
    "\n",
    "\n",
    "\n",
    "1. **Electric_Vehicle_Population_Data**\n",
    "2. **EV_Alternative_Fuel_Charging_Station**\n",
    "3. **ghgp_data_carbon_2022**\n",
    "4. **Electric_Vehicle_Population_Size_History_By_County**\n",
    "\n",
    "\n",
    "Each table holds information pertinent to the overarching question of the relationship between EVs and environmental impact.\n",
    "\n",
    "The following is the breakdown for each table, including some reasons for choosing to keep the information we did.\n",
    "\n",
    "\n",
    "> **`Electric_Vehicle_Population_Data`**\n",
    "\n",
    "- textextextext\n",
    "- textextextext\n",
    "- textextextext\n",
    "\n",
    "> **`EV_Alternative_Fuel_Charging_Station`**\n",
    "\n",
    "- textextextext\n",
    "- textextextext\n",
    "- textextextext\n",
    "\n",
    "> **`ghgp_data_carbon_2022`**\n",
    "\n",
    "- textextextext\n",
    "- textextextext\n",
    "- textextextext\n",
    "\n",
    "> **`Electric_Vehicle_Population_Size_History_By_County`**\n",
    "\n",
    "- textextextext\n",
    "- textextextext\n",
    "- textextextext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(to be edited further)**\n",
    "\n",
    "![ERDV with code](https://i.imgur.com/aXWjnSz.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(to be edited further)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### III. **Data and Delivery**\n",
    "* *   * * "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **1. Data Preparation**\n",
    "\n",
    "\n",
    "**(to be edited further)**\n",
    "\n",
    "Before we could load the data into tables, we first had to clean the datasets given to us.\n",
    "\n",
    "Because our datasets were CSV files that were already fairly clean to begin with, we initally opted to clean the data manually via Excel.\n",
    "\n",
    "textextextext.\n",
    "* *   * * "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **2. Data Validation using Great Expectations**\n",
    "\n",
    "`(to be edited further, but great guide on Great Expectations using a csv file as an example below ->` \n",
    "\n",
    "https://github.com/ismaildawoodjee/Great-Expectations-for-CSV?tab=readme-ov-file#data-preparation\n",
    "\n",
    "\n",
    "Ensuring data quality is a crucial step in any data engineering project, especially when applying the skill outside of the classroom. Ultimately, the goal of any data collection is for stakeholders to make strategic business decisions. If the quality of data is subpar, then inaccurate values can lead to poor decisions being made due to incorrect and inaccurate data. It should not come as a surprise that as data scientists, we seek to avoid this outcome.\n",
    "\n",
    "Our original datasets from Kaggle and the US Census are all single flat file CSVs. Validating this data can be tricky, and it took considerable research to decide how to approach this aspect of the project. Ultimately, we decided to use Great Expectations for its automated testing, for the purpose of validating, profiling and documenting our data. The aim was to catch any presence of null or unclean data missed in the manual cleaning, and to test, validate and document data quality issues using Great Expectations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Initializing the Great Expectations Workspace**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Deploy Great Expectations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Validate new batch of data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* *   * * \n",
    "##### **3. Reading the Data and Displaying It**\n",
    "\n",
    "\n",
    "**(to be edited further)**\n",
    "\n",
    "Things to add to this section (From project overview):\n",
    "\n",
    "- A method for reading data from the database\n",
    "\n",
    "\n",
    "- A method for displaying it for future use, such as:\n",
    "    - Pandas DataFrame\n",
    "    - Flask API with JSON output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
